{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSCE 5290 NLP - Final Project - Text Summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wOtlDcthFxip",
        "g60ui_SCy6nz"
      ],
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUValOzcHtEK"
      },
      "source": [
        "#Import the Libraries and load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "_Jpu8qLEFxcY"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Attention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cSXIcXP9tit",
        "outputId": "27fde056-7f6c-49a5-bc29-adb66d582d1e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wnK5o4Z1Fxcj"
      },
      "source": [
        "data=pd.read_csv(\"/content/drive/MyDrive/CSCE 5290 - NLP/Reviews.csv\",nrows=100000)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Cjul88oOFxcr"
      },
      "source": [
        "# Drop duplicates and NA\n",
        "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
        "data.dropna(axis=0,inplace=True)#dropping na"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "__fy-JxTFxc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e0f7f59-8341-474e-d173-155ec513deef"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 88421 entries, 0 to 99999\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   Id                      88421 non-null  int64 \n",
            " 1   ProductId               88421 non-null  object\n",
            " 2   UserId                  88421 non-null  object\n",
            " 3   ProfileName             88421 non-null  object\n",
            " 4   HelpfulnessNumerator    88421 non-null  int64 \n",
            " 5   HelpfulnessDenominator  88421 non-null  int64 \n",
            " 6   Score                   88421 non-null  int64 \n",
            " 7   Time                    88421 non-null  int64 \n",
            " 8   Summary                 88421 non-null  object\n",
            " 9   Text                    88421 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 7.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0xLYACiFxdJ"
      },
      "source": [
        "#Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0s6IY-x2FxdL"
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11vGn9ww6XgS",
        "outputId": "4e67ed60-1db0-4886-aa65-fc6c462bcbc0"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcYS4XxlHlkk"
      },
      "source": [
        "**Text cleaning:**\n",
        "\n",
        "1.Convert to lowercase\n",
        "\n",
        "2.Remove HTML\n",
        "\n",
        "3.Replace contractions\n",
        "\n",
        "5.Remove text inside parenthesis\n",
        "\n",
        "6.Remove punctuations and special characters\n",
        "\n",
        "7.Remove stopwords\n",
        "\n",
        "8.Remove short words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XZr-u3OEFxdT"
      },
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def text_cleaner(text,num):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
        "    if(num==0):\n",
        "        tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    else:\n",
        "        tokens=newString.split()\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                                 #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "A2QAeCHWFxdY"
      },
      "source": [
        "#call the function for reviews\n",
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t,0)) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NCAIkhWbFxdh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8028c6a6-0094-4da9-9709-4e35fc27a375"
      },
      "source": [
        "cleaned_text[:5]  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
              " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
              " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
              " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
              " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GsRXocxoFxd-"
      },
      "source": [
        "#call the function for summaries\n",
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(text_cleaner(t,1))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jQJdZcAzFxee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe2707e-7543-4c44-b3d0-2351f922f186"
      },
      "source": [
        "cleaned_summary[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good quality dog food',\n",
              " 'not as advertised',\n",
              " 'delight says it all',\n",
              " 'cough medicine',\n",
              " 'great taffy',\n",
              " 'nice taffy',\n",
              " 'great just as good as the expensive brands',\n",
              " 'wonderful tasty taffy',\n",
              " 'yay barley',\n",
              " 'healthy dog food']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "L1zLpnqsFxey"
      },
      "source": [
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sYK390unFxfA"
      },
      "source": [
        "# Drop empty rows, if any\n",
        "data.replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm8Fk2TCL7Sp"
      },
      "source": [
        "#Understanding the distribution of the sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MdF76AHHFxgw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "b5bcacfc-81c5-4966-b933-3d8e740739d6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['cleaned_summary']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7JRjwdIOFxg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca329b8-d43b-4b80-c488-8b7415ab1c06"
      },
      "source": [
        "# Check % of word bellow threshold (in this case 8)\n",
        "thresh = 8\n",
        "cnt=0\n",
        "for i in data['cleaned_summary']:\n",
        "    if len(i.split()) <= thresh:\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(data['cleaned_summary']))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9424907471335922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZKD5VOWqFxhC"
      },
      "source": [
        "# Set review and summary max lengths\n",
        "max_text_len=30\n",
        "max_summary_len=8"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yY0tEJP0FxhI"
      },
      "source": [
        "cleaned_text = np.array(data['cleaned_text'])\n",
        "cleaned_summary = np.array(data['cleaned_summary'])\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "df = pd.DataFrame({'text':short_text,'summary':short_summary})"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EwLUH78CFxhg"
      },
      "source": [
        "# Add <sos> and <eos> tokens\n",
        "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uYv62eo0c5CV",
        "outputId": "15dbacaa-fb24-49a8-bab4-8f5c2eaa4a82"
      },
      "source": [
        "df['summary'][1]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sostok not as advertised eostok'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk1t30ryI-Yj"
      },
      "source": [
        "# Splitting the dataset in 80% train, 10% validation and 10% test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RakakKHcFxhl"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_test,y_tr,y_test=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True) "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTPnExR0JK0h"
      },
      "source": [
        "x_tr,x_val,y_tr,y_val=train_test_split(x_tr,y_tr,test_size=0.1,random_state=0,shuffle=True) "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq1mqyOHOtIl"
      },
      "source": [
        "#Preparing the Tokenizer\n",
        "\n",
        "**Text Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oRHTgX6hFxhq"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzvLwYL_PDcx"
      },
      "source": [
        "**Check for rarewords (threshold = 4)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y8KronV2Fxhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ca9df0-2a11-4f36-ee2f-c6c6573b5ba7"
      },
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of rare words in vocabulary: 66.10591112235433\n",
            "Total Coverage of rare words: 3.1257069330954916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "J2giEsF3Fxh3"
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "x_test_seq   =   x_tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "x_test   =   pad_sequences(x_test_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DCbGMsm4FxiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06e083a-194e-4a80-c26d-a59babf03feb"
      },
      "source": [
        "x_voc"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8040"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQfKP3sqRxi9"
      },
      "source": [
        "**Summary Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eRHqyBkBFxiJ"
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KInA6O6ZSkJz"
      },
      "source": [
        "**Check for rarewords (threshold = 6)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yzE5OiRLFxiM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "342b9633-61d7-4796-b61c-ea7f1a0b4547"
      },
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of rare words in vocabulary: 78.40975043528728\n",
            "Total Coverage of rare words: 5.679866602763799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-fswLvIgFxiR"
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val)\n",
        "y_test_seq   =   y_tokenizer.texts_to_sequences(y_test)  \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "y_test   =   pad_sequences(y_test_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pR8IX9FRFxiY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bafbf377-8335-4072-b154-7ac4875822b6"
      },
      "source": [
        "# Double check if all sentences have eos token\n",
        "y_tokenizer.word_counts['eostok'],len(y_tr)   "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38207, 38207)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kZ-vW82sFxih"
      },
      "source": [
        "# Delete empty sentences\n",
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cx5NISuMFxik"
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZTGE9NAOeFn"
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_test)):\n",
        "    cnt=0\n",
        "    for j in y_test[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_test=np.delete(y_test,ind, axis=0)\n",
        "x_test=np.delete(x_test,ind, axis=0)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOtlDcthFxip"
      },
      "source": [
        "# First Model: LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zXef38nBFxir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbdde1dd-88f0-496c-ef08-62f70f768002"
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary() "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 30, 100)      804000      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 30, 300),    481200      ['embedding[0][0]']              \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 30, 300),    721200      ['lstm[0][0]']                   \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 100)    186100      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 30, 300),    721200      ['lstm_1[0][0]']                 \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 300),  481200      ['embedding_1[0][0]',            \n",
            "                                 (None, 300),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 300)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, None, 1861)  560161      ['lstm_3[0][0]']                 \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,955,061\n",
            "Trainable params: 3,955,061\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Lwfi1Fm8Fxiz"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-A3J92MUljB"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ETnPzA4OFxi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413285cf-0517-4061-848d-3497302f8125"
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=10,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "291/291 [==============================] - 150s 473ms/step - loss: 2.8468 - val_loss: 2.5315\n",
            "Epoch 2/10\n",
            "291/291 [==============================] - 137s 470ms/step - loss: 2.5523 - val_loss: 2.4061\n",
            "Epoch 3/10\n",
            "291/291 [==============================] - 136s 468ms/step - loss: 2.4318 - val_loss: 2.3121\n",
            "Epoch 4/10\n",
            "291/291 [==============================] - 136s 468ms/step - loss: 2.3328 - val_loss: 2.2458\n",
            "Epoch 5/10\n",
            "291/291 [==============================] - 136s 468ms/step - loss: 2.2544 - val_loss: 2.1717\n",
            "Epoch 6/10\n",
            "291/291 [==============================] - 137s 469ms/step - loss: 2.1900 - val_loss: 2.1409\n",
            "Epoch 7/10\n",
            "291/291 [==============================] - 136s 468ms/step - loss: 2.1401 - val_loss: 2.0999\n",
            "Epoch 8/10\n",
            "291/291 [==============================] - 137s 470ms/step - loss: 2.0977 - val_loss: 2.0901\n",
            "Epoch 9/10\n",
            "291/291 [==============================] - 136s 468ms/step - loss: 2.0604 - val_loss: 2.0599\n",
            "Epoch 10/10\n",
            "291/291 [==============================] - 136s 467ms/step - loss: 2.0265 - val_loss: 2.0474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "humu8M_70RyZ"
      },
      "source": [
        "**Diagnostic plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tDTNLAURFxjE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "82c16469-12c6-4ce9-f9ed-5a6ee1b2bf7c"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sBX0zZnOFxjW"
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM_nU_VvFxjq"
      },
      "source": [
        "**Inference for LSTM model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6f6TTFnBFxj6"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "    \n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "        \n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aAUntznIFxj9"
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx2Rg5HkeK-A"
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "#attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "#decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "#decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gM4ALyfWwA9"
      },
      "source": [
        "**Testing the model**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BUtQmQTmFxkI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b69bd9-ad1e-4c33-cdd3-c8bef0becf10"
      },
      "source": [
        "for i in range(10):\n",
        "    print(\"Review:\",seq2text(x_test[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_test[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_test[i].reshape(1,max_text_len)))\n",
        "    #print(\"\\n\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: great healthy chew old beagle rio loves taste sure beats arm \n",
            "Original summary: yummy \n",
            "Predicted summary:  great for training\n",
            "Review: thank goodness carbonated drink tasty without additives taste like cherry drinks slightly lighter flavoring although less half volume normal wonder things good comes small size least recycled \n",
            "Original summary: it is tasty \n",
            "Predicted summary:  great taste\n",
            "Review: extra bold coffee one favorites extra bold could compared bold coffee regular coffee brewer \n",
            "Original summary: great coffee for keurig brewer \n",
            "Predicted summary:  great coffee\n",
            "Review: like flavored coffee taste like coffee may could taste coffee travel size brew smaller brew sizes bit better \n",
            "Original summary: too much caramel cream not enough coffee \n",
            "Predicted summary:  good coffee\n",
            "Review: slightly overpriced one kitty last month less pound bags recently purchased petsmart dollars pound bag \n",
            "Original summary: great food \n",
            "Predicted summary:  good product\n",
            "Review: boss likes smarties saw giant smarties thought would funny handed small said call handing giant thought looked \n",
            "Original summary: big hit at the office \n",
            "Predicted summary:  not what expected\n",
            "Review: grateful amazing mix used make best gluten free products break us gluten free miss real mixes ones market dont trick like \n",
            "Original summary: amazing \n",
            "Predicted summary:  great snack\n",
            "Review: like even regular bisquick mix make pancakes taste closer scratch wheat flour pancakes members family tried yet used pizza crust biscuits \n",
            "Original summary: just about perfect for pancakes \n",
            "Predicted summary:  great taste\n",
            "Review: product wonderful like hot also good mixed ice milk blender love \n",
            "Original summary: great \n",
            "Predicted summary:  great product\n",
            "Review: better tasting cheaper hr energy experience energy boost equal hr energy lasts long however prefer taste saves money \n",
            "Original summary: better tasting than energy \n",
            "Predicted summary:  good price\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6I_-wS0Ub_Y",
        "outputId": "8c4dede7-ce04-4d59-d973-73d2a616ea38"
      },
      "source": [
        "# Save results in a dataframe for analysis\n",
        "original = []\n",
        "predicted = []\n",
        "for i in range(1000):  \n",
        "  original.append(seq2summary(y_test[i]))\n",
        "  predicted.append(decode_sequence(x_test[i].reshape(1,max_text_len)))\n",
        "\n",
        "df_results_lstm = pd.DataFrame(list(zip(original, predicted)), columns =['Original', 'Predicted'])\n",
        "df_results_lstm.info "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of                                       Original            Predicted\n",
              "0                                       yummy    great for training\n",
              "1                                 it is tasty           great taste\n",
              "2              great coffee for keurig brewer          great coffee\n",
              "3    too much caramel cream not enough coffee           good coffee\n",
              "4                                  great food          good product\n",
              "..                                         ...                  ...\n",
              "995                              tastes great                  good\n",
              "996                                  pretzels           great snack\n",
              "997                           is not half bad    good but not great\n",
              "998                      very unique beverage               not bad\n",
              "999               the best stuff in the world             best ever\n",
              "\n",
              "[1000 rows x 2 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuKavKGH4snw"
      },
      "source": [
        "filename = '/content/drive/MyDrive/CSCE 5290 - NLP/CSCE 5290 - Final Project/results_lstm_final.csv'\n",
        "df_results_lstm.to_csv(filename)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1kmmUq3fmCc"
      },
      "source": [
        "# Bidirectional LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnydvhWXske2"
      },
      "source": [
        "from tensorflow.keras.layers import Bidirectional"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMQeyAaNslHG",
        "outputId": "72223bce-b710-4cab-d050-0f3c5ff42261"
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = Bidirectional(LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4))\n",
        "encoder_output1, forward_h1, forward_c1, backward_h1, backward_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = Bidirectional(LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4))\n",
        "encoder_output2, forward_h2, forward_c2, backward_h2, backward_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4))\n",
        "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_lstm2(encoder_output2)\n",
        "\n",
        "state_h = Concatenate()([forward_h, backward_h])\n",
        "state_c = Concatenate()([forward_c, backward_c])\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim*2, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "#decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary() "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 30, 100)      804000      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  [(None, 30, 600),    962400      ['embedding[0][0]']              \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  [(None, 30, 600),   2162400     ['bidirectional[0][0]',          \n",
            " )                               (None, 300),                     'bidirectional_1[0][0]']        \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 100)    186100      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 600)          0           ['bidirectional_1[1][1]',        \n",
            "                                                                  'bidirectional_1[1][3]']        \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 600)          0           ['bidirectional_1[1][2]',        \n",
            "                                                                  'bidirectional_1[1][4]']        \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 600),  1682400     ['embedding_1[0][0]',            \n",
            "                                 (None, 600),                     'concatenate[0][0]',            \n",
            "                                 (None, 600)]                     'concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, None, 1861)  1118461     ['lstm_3[0][0]']                 \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,915,761\n",
            "Trainable params: 6,915,761\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyW185NZv1vR"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CzBnXFEv7c8"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYamMmO1wA29",
        "outputId": "b7b0541d-4ef0-4ca0-8020-5c49499579c0"
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=10,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "291/291 [==============================] - 279s 896ms/step - loss: 2.8275 - val_loss: 2.5274\n",
            "Epoch 2/10\n",
            "291/291 [==============================] - 260s 892ms/step - loss: 2.5132 - val_loss: 2.3591\n",
            "Epoch 3/10\n",
            "291/291 [==============================] - 260s 893ms/step - loss: 2.3740 - val_loss: 2.2706\n",
            "Epoch 4/10\n",
            "291/291 [==============================] - 258s 888ms/step - loss: 2.2833 - val_loss: 2.1979\n",
            "Epoch 5/10\n",
            "291/291 [==============================] - 257s 882ms/step - loss: 2.2206 - val_loss: 2.1597\n",
            "Epoch 6/10\n",
            "291/291 [==============================] - 256s 880ms/step - loss: 2.1705 - val_loss: 2.1328\n",
            "Epoch 7/10\n",
            "291/291 [==============================] - 258s 885ms/step - loss: 2.1238 - val_loss: 2.1182\n",
            "Epoch 8/10\n",
            "291/291 [==============================] - 252s 866ms/step - loss: 2.0810 - val_loss: 2.0871\n",
            "Epoch 9/10\n",
            "291/291 [==============================] - 251s 864ms/step - loss: 2.0393 - val_loss: 2.0741\n",
            "Epoch 10/10\n",
            "291/291 [==============================] - 251s 863ms/step - loss: 2.0020 - val_loss: 2.0478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "AAxTtuj9wVBJ",
        "outputId": "12197a62-22f1-4c23-a64a-ddbaf373164d"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NrsKHiivwteS"
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L51of0ow88P"
      },
      "source": [
        "**Inference for LSTM Bidirectional model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TlUoPMqEOWce"
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fcdij1kMHgv"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_fh, e_fc, e_bh, e_bc = encoder_model.predict(input_seq)\n",
        "    \n",
        "    e_h = Concatenate()([e_fh, e_bh])\n",
        "    e_c = Concatenate()([e_fc, e_bc])\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "    \n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "        \n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nLDJLF1x5f-y"
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "#encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, forward_h, forward_c, backward_h, backward_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim*2,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim*2,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim*2))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "#attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "#decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "#decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p_e2Er_xxPj",
        "outputId": "0c763552-eb82-49ae-8b1d-649709205a07"
      },
      "source": [
        "for i in range(10):\n",
        "    print(\"Review:\",seq2text(x_test[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_test[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_test[i].reshape(1,max_text_len)))\n",
        "    #print(\"\\n\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: great healthy chew old beagle rio loves taste sure beats arm \n",
            "Original summary: yummy \n",
            "Predicted summary:  great for my dog\n",
            "Review: thank goodness carbonated drink tasty without additives taste like cherry drinks slightly lighter flavoring although less half volume normal wonder things good comes small size least recycled \n",
            "Original summary: it is tasty \n",
            "Predicted summary:  great product\n",
            "Review: extra bold coffee one favorites extra bold could compared bold coffee regular coffee brewer \n",
            "Original summary: great coffee for keurig brewer \n",
            "Predicted summary:  great coffee\n",
            "Review: like flavored coffee taste like coffee may could taste coffee travel size brew smaller brew sizes bit better \n",
            "Original summary: too much caramel cream not enough coffee \n",
            "Predicted summary:  good coffee\n",
            "Review: slightly overpriced one kitty last month less pound bags recently purchased petsmart dollars pound bag \n",
            "Original summary: great food \n",
            "Predicted summary:  great product\n",
            "Review: boss likes smarties saw giant smarties thought would funny handed small said call handing giant thought looked \n",
            "Original summary: big hit at the office \n",
            "Predicted summary:  not bad\n",
            "Review: grateful amazing mix used make best gluten free products break us gluten free miss real mixes ones market dont trick like \n",
            "Original summary: amazing \n",
            "Predicted summary:  great gluten free pasta\n",
            "Review: like even regular bisquick mix make pancakes taste closer scratch wheat flour pancakes members family tried yet used pizza crust biscuits \n",
            "Original summary: just about perfect for pancakes \n",
            "Predicted summary:  great snack\n",
            "Review: product wonderful like hot also good mixed ice milk blender love \n",
            "Original summary: great \n",
            "Predicted summary:  great product\n",
            "Review: better tasting cheaper hr energy experience energy boost equal hr energy lasts long however prefer taste saves money \n",
            "Original summary: better tasting than energy \n",
            "Predicted summary:  good product\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS5OCOhmx8RS",
        "outputId": "ff2ab274-9a16-4a6b-aa41-3f6fd272c5a8"
      },
      "source": [
        "# Save results in a dataframe for analysis\n",
        "original = []\n",
        "predicted = []\n",
        "for i in range(1000):  \n",
        "  original.append(seq2summary(y_test[i]))\n",
        "  predicted.append(decode_sequence(x_test[i].reshape(1,max_text_len)))\n",
        "\n",
        "df_results_bidirectional_lstm = pd.DataFrame(list(zip(original, predicted)), columns =['Original', 'Predicted'])\n",
        "df_results_bidirectional_lstm.info "
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of                                       Original            Predicted\n",
              "0                                       yummy      great for my dog\n",
              "1                                 it is tasty         great product\n",
              "2              great coffee for keurig brewer          great coffee\n",
              "3    too much caramel cream not enough coffee           good coffee\n",
              "4                                  great food         great product\n",
              "..                                         ...                  ...\n",
              "995                              tastes great           great taste\n",
              "996                                  pretzels           great snack\n",
              "997                           is not half bad               not bad\n",
              "998                      very unique beverage    good but not great\n",
              "999               the best stuff in the world             great for\n",
              "\n",
              "[1000 rows x 2 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJFmMvytyGPQ"
      },
      "source": [
        "filename = '/content/drive/MyDrive/CSCE 5290 - NLP/CSCE 5290 - Final Project/results_bidirectional_lstm_final.csv'\n",
        "df_results_bidirectional_lstm.to_csv(filename)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_8yOvr1aUEL"
      },
      "source": [
        "# Transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBNNX0hgZZIg",
        "outputId": "38d76f9b-8f30-4225-a546-164196507a86"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 59.8 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 66.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptGCNiCQadzf"
      },
      "source": [
        "import transformers\n",
        "from transformers import pipeline"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1L6g-UbauUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3309c62c-491d-4e80-af5c-3065555d3e01"
      },
      "source": [
        "# Limiting the summary between 2 and 8 words to be comparable with previous models\n",
        "max_summary_len = 8\n",
        "min_summary_len = 2\n",
        "original = []\n",
        "predicted = []\n",
        "summarizer = pipeline('summarization')\n",
        "for i in range(500):\n",
        "  review = df_for_pretrained['Text'][i]\n",
        "  summary = summarizer(review, min_length=min_summary_len, max_length=max_summary_len) # call the summarizer on each review\n",
        "  original.append(review)\n",
        "  predicted.append(summary)\n",
        "\n",
        "df_results_pretrained_transformer = pd.DataFrame(list(zip(original, predicted)), columns =['Original', 'Predicted'])\n",
        "df_results_pretrained_transformer.info "
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of                                                                                                                                                                                                     Original                                            Predicted\n",
              "0    I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...   [{'summary_text': ' The product looks more like'}]\n",
              "1             Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".  [{'summary_text': ' Product arrived labeled as J'}]\n",
              "2    This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...              [{'summary_text': ' This is a light,'}]\n",
              "3    If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...  [{'summary_text': ' The flavor is very medicinal'}]\n",
              "4                                                               Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.                [{'summary_text': ' Great taffy at'}]\n",
              "..                                                                                                                                                                                                       ...                                                  ...\n",
              "495                         i rarely eat chips but i saw these and tried them. they are really amazing. i love cheddar too, but the chips are really thin and crunch and delicious flavor. i recommend them.        [{'summary_text': ' i rarely eat chips but'}]\n",
              "496  This is easily the best potato chip that I have ever had.  Look at the ingredients:  Ginger and 3 types of hot pepper.  How can you go wrong?<br /><br />Obviously, not for you if you don't like sp...       [{'summary_text': ' This is easily the best'}]\n",
              "497  Kettle Chips Spicy Thai potato chips have the perfect amount of sweet, savory and spicy-- everything you'd want in a good meal or better yet...a potato chip.  Since these are kettle-cooked, the ch...       [{'summary_text': ' Spicy Thai potato chips'}]\n",
              "498  Okay, I should not eat potato chips, nor should anyone.<br />But these are so spicy, I would find it hard to eat<br />very many. That makes them an indulgence that<br />rescues some people from ov...           [{'summary_text': ' These are so spicy,'}]\n",
              "499  I don't write very many reviews but I have to say that Kettle Brand chips are the best I have ever tasted.  Every flavor is dynamite.  If you are feeling iffy about honey dijon, I would recommend ...        [{'summary_text': ' Kettle Brand chips are'}]\n",
              "\n",
              "[500 rows x 2 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khk9SvoUCjzW"
      },
      "source": [
        "filename = '/content/drive/MyDrive/CSCE 5290 - NLP/CSCE 5290 - Final Project/results_pretrained_transformer.csv'\n",
        "df_results_pretrained_transformer.to_csv(filename)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0YF-zR8fy-O"
      },
      "source": [
        "# Calculating ROUGE-1 and ROUGE-L metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIzMG4vTfxvJ",
        "outputId": "87e3df8d-3373-4294-e1f9-61fd142706bf"
      },
      "source": [
        "pip install rouge-score"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (0.12.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score) (3.2.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.19.5)\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn_sVFH0gGX5"
      },
      "source": [
        "from rouge_score import rouge_scorer\n",
        "import pandas as pd"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFX5rykwm8l0"
      },
      "source": [
        "**ROUGE for LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IahedjvVgLbN"
      },
      "source": [
        "filename = '/content/drive/MyDrive/CSCE 5290 - NLP/CSCE 5290 - Final Project/results_lstm_final.csv'\n",
        "df = pd.read_csv(filename)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRYmn-JLnB8l",
        "outputId": "3f88b6ed-90ca-40e2-c9c6-94a95f914ea7"
      },
      "source": [
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "fscore_R1 = 0\n",
        "fscore_RL = 0\n",
        "for item in range(len(df)):\n",
        "  scores = scorer.score(df['Original'][item], df['Predicted'][item])\n",
        "  fscore_R1 += scores['rouge1'].fmeasure\n",
        "  fscore_RL += scores['rougeL'].fmeasure\n",
        "fscore_R1 /= len(df)\n",
        "fscore_RL /= len(df)\n",
        "print(fscore_R1, fscore_RL)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12872301587301607 0.12821507936507953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHg6k4tKp7Bl"
      },
      "source": [
        "**ROUGE for Bidirectional LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XzHQJUKprgf"
      },
      "source": [
        "filename = '/content/drive/MyDrive/CSCE 5290 - NLP/CSCE 5290 - Final Project/results_bidirectional_lstm_final.csv'\n",
        "df = pd.read_csv(filename)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fumGPHw5qYge",
        "outputId": "707910f0-6aac-4f51-817c-c626a70b4849"
      },
      "source": [
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "fscore_R1 = 0\n",
        "fscore_RL = 0\n",
        "for item in range(len(df)):\n",
        "  scores = scorer.score(df['Original'][item], df['Predicted'][item])\n",
        "  fscore_R1 += scores['rouge1'].fmeasure\n",
        "  fscore_RL += scores['rougeL'].fmeasure\n",
        "fscore_R1 /= len(df)\n",
        "fscore_RL /= len(df)\n",
        "print(fscore_R1, fscore_RL)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12554336219336235 0.12442431457431473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7PWxDoFDU3t"
      },
      "source": [
        "**ROUGE for pre-trained transformer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqcnm0vOC0vS"
      },
      "source": [
        "filename = '/content/drive/MyDrive/CSCE 5290 - NLP/CSCE 5290 - Final Project/results_pretrained_transformer.csv'\n",
        "df = pd.read_csv(filename)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt6duiP1DHHD",
        "outputId": "e0240c2c-df79-46b3-f7e5-96732277ef4c"
      },
      "source": [
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "fscore_R1 = 0\n",
        "fscore_RL = 0\n",
        "for item in range(len(df)):\n",
        "  scores = scorer.score(df['Original'][item], df['Predicted'][item])\n",
        "  fscore_R1 += scores['rouge1'].fmeasure\n",
        "  fscore_RL += scores['rougeL'].fmeasure\n",
        "fscore_R1 /= len(df)\n",
        "fscore_RL /= len(df)\n",
        "print(fscore_R1, fscore_RL)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.16317665154854083 0.1616761774643195\n"
          ]
        }
      ]
    }
  ]
}